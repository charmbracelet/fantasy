---
version: 2
interactions:
- id: 0
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 550
    host: generativelanguage.googleapis.com
    body: |
      {"contents":[{"parts":[{"text":"What's the weather in Florence, Italy?"}],"role":"user"}],"generationConfig":{"thinkingConfig":{"includeThoughts":true,"thinkingBudget":128}},"systemInstruction":{"parts":[{"text":"You are a helpful assistant"}],"role":"user"},"toolConfig":{"functionCallingConfig":{"mode":"AUTO"}},"tools":[{"functionDeclarations":[{"description":"Get weather information for a location","name":"weather","parameters":{"properties":{"location":{"description":"the city","type":"STRING"}},"required":["location"],"type":"OBJECT"}}]}]}
    form:
      alt:
      - sse
    headers:
      Content-Type:
      - application/json
      User-Agent:
      - google-genai-sdk/1.29.0 gl-go/go1.25.1
    url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse
    method: POST
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: -1
    body: "data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"**Investigating Weather Inquiries**\\n\\nI've determined the user is seeking weather data for Florence, Italy. The \\\"weather\\\" tool seems appropriate, and I'll configure its \\\"location\\\" parameter accordingly to gather the requested information. This seems straightforward.\\n\\n\\n\",\"thought\": true}],\"role\": \"model\"},\"index\": 0}],\"usageMetadata\": {\"promptTokenCount\": 54,\"totalTokenCount\": 122,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 54}],\"thoughtsTokenCount\": 68},\"modelVersion\": \"gemini-2.5-flash\",\"responseId\": \"1dH5aLdlu-fszw_R-5iICw\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"**Clarifying Location Details**\\n\\nI have confirmed the user's focus is on weather data, specifically in Florence, Italy. Utilizing the `weather` tool is the logical next step. I'm focusing now on accurately configuring the `location` parameter within the tool, ensuring the prompt for \\\"Florence, Italy\\\" is correctly processed. This refined approach solidifies the connection between the user's intent and tool application.\\n\\n\\n\",\"thought\": true}],\"role\": \"model\"},\"index\": 0}],\"usageMetadata\": {\"promptTokenCount\": 54,\"totalTokenCount\": 137,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 54}],\"thoughtsTokenCount\": 83},\"modelVersion\": \"gemini-2.5-flash\",\"responseId\": \"1dH5aLdlu-fszw_R-5iICw\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"functionCall\": {\"name\": \"weather\",\"args\": {\"location\": \"Florence, Italy\"}},\"thoughtSignature\": \"CiQB0e2Kb9hi6EZcilsj+31+JVZ7CCByLgkmuNyInNF9Jk7ZYkkKZwHR7Ypv/Wt/XyxDgXKh2VbOdJFhhMduABt8qAJIEDD0z6fFQS5W1CMmYWEPduHvGAtDaHd6xyYM3EygM6WbB4I7lThasv2V+lVKac8WEoQeO2QBXNVQOzjb2UosWr+LiUTx87Xd43wKiwIB0e2Kb1fdQ2tOU+4YfSYRgJ8Du9zWgH9oTtFKGyqd3i5vS1T5+f+3KZZgEQcsJEfaRGnOMUzef50UMf0guk8KkzzNTWrIAKX/8ADI98S3dqYCyWa14ePKXLyOcSItiHfMfh5lEEjHnJPoLch/nn2Pc1f9r+xgK9lXtrlIvBCvMI5hIv+5U90bX2zDPIkuSV2Nrzst9TayGjXeaUCRgRmKQeVz8QODcSz1bGpdF95TRZ7pjn5qgUWYHds0UGwrgdnSP20mB7WyM5GMet9olZGxzO/o7Uy2cFvkg1Y3h8RF6OzgY0MjU6LDNPU2f/YEa8DW1wNLVGDZUyg9SnBlOLSZgYcQ5GBillDwIcsKWwHR7YpvweOODmmbYd8sYQ8QhwNr+nOAua2aT4bgsdScNUwMpZVrYy2dEHujhG9RN9uppP9zVscepQA12M3SsU4iSJzD9T7va68LW2kQWO1FnY5oZjzBP0T1qjE=\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0,\"finishMessage\": \"Model generated function call(s).\"}],\"usageMetadata\": {\"promptTokenCount\": 54,\"candidatesTokenCount\": 13,\"totalTokenCount\": 150,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 54}],\"thoughtsTokenCount\": 83},\"modelVersion\": \"gemini-2.5-flash\",\"responseId\": \"1dH5aLdlu-fszw_R-5iICw\"}\r\n\r\n"
    headers:
      Content-Type:
      - text/event-stream
    status: 200 OK
    code: 200
    duration: 1.469609s
- id: 1
  request:
    proto: HTTP/1.1
    proto_major: 1
    proto_minor: 1
    content_length: 764
    host: generativelanguage.googleapis.com
    body: |
      {"contents":[{"parts":[{"text":"What's the weather in Florence, Italy?"}],"role":"user"},{"parts":[{"functionCall":{"args":{"location":"Florence, Italy"},"id":"1","name":"weather"}}],"role":"model"},{"parts":[{"functionResponse":{"id":"1","name":"weather","response":{"result":"40 C"}}}],"role":"user"}],"generationConfig":{"thinkingConfig":{"includeThoughts":true,"thinkingBudget":128}},"systemInstruction":{"parts":[{"text":"You are a helpful assistant"}],"role":"user"},"toolConfig":{"functionCallingConfig":{"mode":"AUTO"}},"tools":[{"functionDeclarations":[{"description":"Get weather information for a location","name":"weather","parameters":{"properties":{"location":{"description":"the city","type":"STRING"}},"required":["location"],"type":"OBJECT"}}]}]}
    form:
      alt:
      - sse
    headers:
      Content-Type:
      - application/json
      User-Agent:
      - google-genai-sdk/1.29.0 gl-go/go1.25.1
    url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:streamGenerateContent?alt=sse
    method: POST
  response:
    proto: HTTP/2.0
    proto_major: 2
    proto_minor: 0
    content_length: -1
    body: "data: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \"The weather in Florence\"}],\"role\": \"model\"},\"index\": 0}],\"usageMetadata\": {\"promptTokenCount\": 84,\"candidatesTokenCount\": 4,\"totalTokenCount\": 88,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 84}]},\"modelVersion\": \"gemini-2.5-flash\",\"responseId\": \"19H5aPmSCc3rkdUPy4u8-AI\"}\r\n\r\ndata: {\"candidates\": [{\"content\": {\"parts\": [{\"text\": \", Italy is 40 degrees Celsius.\"}],\"role\": \"model\"},\"finishReason\": \"STOP\",\"index\": 0}],\"usageMetadata\": {\"promptTokenCount\": 84,\"candidatesTokenCount\": 13,\"totalTokenCount\": 97,\"promptTokensDetails\": [{\"modality\": \"TEXT\",\"tokenCount\": 84}]},\"modelVersion\": \"gemini-2.5-flash\",\"responseId\": \"19H5aPmSCc3rkdUPy4u8-AI\"}\r\n\r\n"
    headers:
      Content-Type:
      - text/event-stream
    status: 200 OK
    code: 200
    duration: 560.002084ms
