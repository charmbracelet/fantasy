---
version: 2
interactions:
  - id: 0
    request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 462
        host: ""
        body: '{"messages":[{"content":"You are a helpful assistant","role":"system"},{"content":"What''s the weather in Florence, Italy?","role":"user"}],"model":"grok-3-mini","reasoning_effort":"high","tool_choice":"auto","tools":[{"function":{"name":"weather","strict":false,"description":"Get weather information for a location","parameters":{"properties":{"location":{"description":"the city","type":"string"}},"required":["location"],"type":"object"}},"type":"function"}]}'
        headers:
            Accept:
              - application/json
            Content-Type:
              - application/json
            User-Agent:
              - OpenAI/Go 2.3.0
        url: https://api.x.ai/v1/chat/completions
        method: POST
    response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        content_length: -1
        uncompressed: true
        body: '{"id":"c252909e-30f3-f72d-b31e-96f598e4e7bc_us-east-1","object":"chat.completion","created":1758794759,"model":"grok-3-mini-high","choices":[{"index":0,"message":{"role":"assistant","content":"","reasoning_content":"First, the user is asking for the weather in Florence, Italy. I have an available function called \"weather\" that can get weather information for a location. The function requires a \"location\" parameter, which is described as \"the city\".\n\nThe user''s query specifies \"Florence, Italy\". This provides both the city name and the country, but the function parameter is just \"location\" described as \"the city\". I need to see if this is inferable.\n\nThe description says \"the city\", so I should probably use \"Florence\" as the location, since it''s the city name. Including the country might not be necessary, but it could help if there are multiple cities with the same name. However, the function parameter is defined as a string for the city, and it doesn''t specify handling country or other details. To keep it simple, I can use \"Florence\" as the location.\n\nThe required parameters are [\"location\"], and it''s provided. The location is \"Florence\", and since the user specified \"Italy\", it''s clear which Florence they mean. I don''t need to ask for clarification.\n\nThe instruction says: \"If the user''s query can be addressed using an available function, and all required parameters are provided or obviously inferable, trigger a function call.\" Here, the parameter is inferable as \"Florence\".\n\nI should call the function in the specified JSON format within <function_call> tags.\n\nFunction call format: <function_call>{\"action\": \"weather\", \"action_input\": {\"location\": \"Florence\"}}</function_call>\n\nI need to decide if I should include \"Italy\" in the location. The parameter is described as \"the city\", so probably just \"Florence\" is sufficient. If the function needs more specificity, it might handle it, but based on the description, I''ll stick to what''s required.\n\nAfter calling the function, if this were a multi-turn conversation, I might need to handle the response, but the instruction is to call functions to advance the request. Since this is likely the first step, I''ll call the weather function.\n\nMy response should only contain the function call if I''m deciding to call it, or otherwise respond normally. In this case, I''m calling a function, so I should output only the <function_call> tag with the JSON.\n\nThe instruction says: \"You are only permitted to use the <function_call> tag in your response only if you have made the decision to call a function.\" And \"Keep your response to user clear; please do not make your response verbose!\"\n\nSo, I should not add any extra text; just the function call.\n\nFinal decision: Call the weather function with location as \"Florence\".","tool_calls":[{"id":"call_83674222","function":{"name":"weather","arguments":"{\"location\":\"Florence\"}"},"type":"function"}],"refusal":null},"finish_reason":"tool_calls"}],"usage":{"prompt_tokens":288,"completion_tokens":25,"total_tokens":845,"prompt_tokens_details":{"text_tokens":288,"audio_tokens":0,"image_tokens":0,"cached_tokens":4},"completion_tokens_details":{"reasoning_tokens":532,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0},"num_sources_used":0},"system_fingerprint":"fp_a6fbae1a97"}'
        headers:
            Content-Type:
              - application/json
        status: 200 OK
        code: 200
        duration: 5.270359416s
  - id: 1
    request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 675
        host: ""
        body: '{"messages":[{"content":"You are a helpful assistant","role":"system"},{"content":"What''s the weather in Florence, Italy?","role":"user"},{"tool_calls":[{"id":"call_83674222","function":{"arguments":"{\"location\":\"Florence\"}","name":"weather"},"type":"function"}],"role":"assistant"},{"content":"40 C","tool_call_id":"call_83674222","role":"tool"}],"model":"grok-3-mini","reasoning_effort":"high","tool_choice":"auto","tools":[{"function":{"name":"weather","strict":false,"description":"Get weather information for a location","parameters":{"properties":{"location":{"description":"the city","type":"string"}},"required":["location"],"type":"object"}},"type":"function"}]}'
        headers:
            Accept:
              - application/json
            Content-Type:
              - application/json
            User-Agent:
              - OpenAI/Go 2.3.0
        url: https://api.x.ai/v1/chat/completions
        method: POST
    response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        content_length: -1
        uncompressed: true
        body: '{"id":"0e8b2650-9b58-7a68-0546-5d76ffade4c2_us-east-1","object":"chat.completion","created":1758794765,"model":"grok-3-mini-high","choices":[{"index":0,"message":{"role":"assistant","content":"The weather in Florence, Italy is 40°C.","reasoning_content":"First, the user asked: \"What''s the weather in Florence, Italy?\" I''ve already made a function call to the \"weather\" action with the location \"Florence\". The response from the function is \"40 C\", which I assume means 40 degrees Celsius.\n\nNow, in this multi-turn conversation, I need to continue based on the function''s response. The function call was successful, and I have the weather information. My role is to be a helpful assistant, so I should provide the information to the user in a clear and concise manner.\n\nThe available instructions say: \"Keep your response to user clear; please do not make your response verbose!\" So, I should be direct.\n\nAlso, the function call response is just \"40 C\", but the user specified \"Florence, Italy\". I should confirm or present this information properly, perhaps including the location for clarity.\n\nI don''t need to call another function unless more information is needed or the request isn''t fulfilled. Here, the request was for the weather in Florence, Italy, and I''ve got the data, so I can respond directly.\n\nMy response should not include any verbose text. Just provide the weather information.\n\nFinally, I should not use the <function_call> tag unless I''m calling a function. In this case, I''m not calling any function; I''m responding with the result.\n\nSo, a clear response could be: \"The weather in Florence, Italy is 40°C.\"\n\nThe function response is \"40 C\", which might be shorthand for Celsius. I should use the standard symbol °C for clarity.\n\nEnsure the response is user-friendly.","refusal":null},"finish_reason":"stop"}],"usage":{"prompt_tokens":330,"completion_tokens":11,"total_tokens":660,"prompt_tokens_details":{"text_tokens":330,"audio_tokens":0,"image_tokens":0,"cached_tokens":283},"completion_tokens_details":{"reasoning_tokens":319,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0},"num_sources_used":0},"system_fingerprint":"fp_a6fbae1a97"}'
        headers:
            Content-Type:
              - application/json
        status: 200 OK
        code: 200
        duration: 2.982462291s
