---
version: 2
interactions:
  - id: 0
    request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 494
        host: ""
        body: '{"messages":[{"content":"You are a helpful assistant","role":"system"},{"content":"What''s the weather in Florence, Italy?","role":"user"}],"model":"openai/gpt-5","tool_choice":"auto","tools":[{"function":{"name":"weather","strict":false,"description":"Get weather information for a location","parameters":{"properties":{"location":{"description":"the city","type":"string"}},"required":["location"],"type":"object"}},"type":"function"}],"reasoning":{"effort":"medium"},"usage":{"include":true}}'
        headers:
            Accept:
              - application/json
            Content-Type:
              - application/json
            User-Agent:
              - OpenAI/Go 2.3.0
        url: https://openrouter.ai/api/v1/chat/completions
        method: POST
    response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        content_length: -1
        uncompressed: true
        body: "\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n{\"id\":\"gen-1758710067-0XaYb8CAKeAGdjBnksDD\",\"provider\":\"OpenAI\",\"model\":\"openai/gpt-5\",\"object\":\"chat.completion\",\"created\":1758710067,\"choices\":[{\"logprobs\":null,\"finish_reason\":\"tool_calls\",\"native_finish_reason\":\"completed\",\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"\",\"refusal\":null,\"reasoning\":\"**Fetching weather data**\\n\\nI need to get the weather information for Florence, Italy, as the user requested. I'll use the functions.weather tool and set the location to \\\"Florence, Italy.\\\" I see that there's a multi_tool_use.parallel option, but since I only need one tool here, I'll stick with functions.weather. Once I call it through the commentary channel, I'll retrieve the output. I just hope the data comes back correctly so I can present the weather accurately!\",\"tool_calls\":[{\"id\":\"call_hPeOSCUiY61l9U2MD4Nx8MW5\",\"index\":1,\"type\":\"function\",\"function\":{\"name\":\"weather\",\"arguments\":\"{\\\"location\\\":\\\"Florence, Italy\\\"}\"}}],\"reasoning_details\":[{\"type\":\"reasoning.summary\",\"summary\":\"**Fetching weather data**\\n\\nI need to get the weather information for Florence, Italy, as the user requested. I'll use the functions.weather tool and set the location to \\\"Florence, Italy.\\\" I see that there's a multi_tool_use.parallel option, but since I only need one tool here, I'll stick with functions.weather. Once I call it through the commentary channel, I'll retrieve the output. I just hope the data comes back correctly so I can present the weather accurately!\",\"format\":\"openai-responses-v1\",\"index\":0},{\"type\":\"reasoning.encrypted\",\"data\":\"gAAAAABo08k3O0e00zGtYNZAXav2t2ESbQlgnqjUcmuvXMNiGdkK2w_9Jc9Q9jDaoF343dKdkUm9KMK4BVyJMD-s1LDPXZj1O_1H2DTEJBOhdTlbSkWliV_OlifyVZ8DfET3vxZvNxO-Q_cUNpvn7nsjwjDRJluVFEftsQQy2SfOdPS8qcDBsIMrTpHLSrcL1T39R22YQWhFnCKkF9Z2SsKg6jCqsY4LKSnVIwZ8Gt2kknsnu2_SPfXs4HQlEoU-FTiwaOB1OEULrjSNNoFjZQkQM2k5P5VURUujhFvCeVatdcwIK8TJv4gvSHpGj-SMOYvp10UtEQziiVEnnYCuEJcWMD_krYzHlxgh6n8LlpSAvh3TEEc0iR7xfyu5IPFCNfzC8qE725N9o-i5DrgeUIMxL8_d2Ws5JUTH4_zFsv5p9PRzlN6Hvb0dWPWaJRKpbgs4USPPdLfSkjLA3qS2Heq6wuai7Ad_yhjFFaaFSJW94XHMIc7WWEEPtYx_ZGjzoaa17SfLBUc0oLWIb50TEJPzxMOiAqlIIQYLO9QO6vrB9oUHMZf6jviTYb_BizNt3GSS69Fbj2G94cLuDTVVaRpdFTaHrjvpCvpQch2x4Cg_QG1advr98R-gwY3S5JG8MFgxVD0KqBmq5QPsaJf1soYgRp6PUdAGSooBKutbuAxBIdmE4obanARYtvnCIjrGnM3wCuRTz2Uz88WXSBRkWDDqeqqhw8S_8-1QAbOFy7wU2t-ZZVIiz7Exy8i2FP9aG_9BzJXEWKqMl7uZb6PoJUuzv5pPSFf7ZLxN8mQJPSBGZXrhCs-E5OBIOBZZBRKGCFj5HxPqNuCq4HrhUjWmrdskiKjPktc8vgZOonyw8uMHNERxCxpCQoOYq70maEXRBAMKKnOw3LVediLpcAQWuSaeIRusd_SDYlh8RRgO1Y8mIrymbIpmX8euO_zUGVq_QO_1bCPZbCAiv_8ZLPd_hszETso549oSBETxST2VJP8-7bX4AFY03KJ1lqKM3ct4iyxGsauBPyLtrY92440gAh9bFgJuVdHLcyIBmF9LqeJSMuOne5j3c5D3jHVDz4OubPDJZyib2qgIeOoCvORdIq8qEIIpZiPMs_Y1XNUHIi9jbkLf5KYpiRA2YJjYpE7s6iaLeXt1Gqt7eZ-er6_KBc_xi3r0mGNn0fq2-WLn2CJamDfqWLRklyg3uC2LqUMvr-eFEVp98CFNkFo-MURXQzeP6AVaLU0c8Cz16hb_ZYUOXtheQnyOVxOCmxWqVjXdokcNR0_0SFaa7vEw4n-OpvcyZn2p_062Hj2On44-DANVWn3Fhh9TzlHay1zjkTLu3a-GUTqwsG4aLkE48S_Un8D3VQS78YwvSWMDO40I2oMWquUjQxs6nOKX2OPUv40CK4orzhvMhovb38bEGaF-qn4QsmMyRkNWnaNpwulEZT2sZqoY3PVEH17fnYay4fix_-wPFbETa-jxmKG3ia4gYqDZejIinHf6kbtnMy3JP6zvSLEEqsxlQTI6u5voxA-VvNbwygeXwq_dbj4cGfxQrNT3ro3eu4ubjFejFGPQHZPcenFo6sjvRMrjwV0N4T3jYOh0b_ehXVCZk0WsZ3sGzgab57jyxQ77xq1k5W7NJEzVeqEPlnCM9cvyCILzao152yF4vZhmnzgI\",\"id\":\"rs_68d3c93459b881938af0365b660395b90b0a8539b112155d\",\"format\":\"openai-responses-v1\",\"index\":0}]}}],\"usage\":{\"prompt_tokens\":63,\"completion_tokens\":86,\"total_tokens\":149,\"cost\":0.000469375,\"is_byok\":false,\"prompt_tokens_details\":{\"cached_tokens\":0,\"audio_tokens\":0},\"cost_details\":{\"upstream_inference_cost\":null,\"upstream_inference_prompt_cost\":0.000039375,\"upstream_inference_completions_cost\":0.00043},\"completion_tokens_details\":{\"reasoning_tokens\":64,\"image_tokens\":0}}}"
        headers:
            Content-Type:
              - application/json
        status: 200 OK
        code: 200
        duration: 756.40825ms
  - id: 1
    request:
        proto: HTTP/1.1
        proto_major: 1
        proto_minor: 1
        content_length: 746
        host: ""
        body: '{"messages":[{"content":"You are a helpful assistant","role":"system"},{"content":"What''s the weather in Florence, Italy?","role":"user"},{"tool_calls":[{"id":"call_hPeOSCUiY61l9U2MD4Nx8MW5","function":{"arguments":"{\"location\":\"Florence, Italy\"}","name":"weather"},"type":"function"}],"role":"assistant"},{"content":"40 C","tool_call_id":"call_hPeOSCUiY61l9U2MD4Nx8MW5","role":"tool"}],"model":"openai/gpt-5","tool_choice":"auto","tools":[{"function":{"name":"weather","strict":false,"description":"Get weather information for a location","parameters":{"properties":{"location":{"description":"the city","type":"string"}},"required":["location"],"type":"object"}},"type":"function"}],"usage":{"include":true},"reasoning":{"effort":"medium"}}'
        headers:
            Accept:
              - application/json
            Content-Type:
              - application/json
            User-Agent:
              - OpenAI/Go 2.3.0
        url: https://openrouter.ai/api/v1/chat/completions
        method: POST
    response:
        proto: HTTP/2.0
        proto_major: 2
        proto_minor: 0
        content_length: -1
        uncompressed: true
        body: "\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n\n         \n{\"id\":\"gen-1758710071-YRdc9q1f5SRugr0m3cGe\",\"provider\":\"OpenAI\",\"model\":\"openai/gpt-5\",\"object\":\"chat.completion\",\"created\":1758710071,\"choices\":[{\"logprobs\":null,\"finish_reason\":\"stop\",\"native_finish_reason\":\"completed\",\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"It’s currently about 40°C (104°F) in Florence, Italy. Want details like forecast, humidity, or wind?\",\"refusal\":null,\"reasoning\":\"**Relaying weather information**\\n\\nI called the weather tool, and it returned \\\"40 C.\\\" That seems unusually high! Since my job is to relay the weather, I should only share the temperature. The user asked for the weather in Florence, Italy, so I can simply say, \\\"It's currently about 40°C in Florence, Italy.\\\" I might want to check in and ask if the user wants more details, but they didn't explicitly ask for them. I'll keep the formatting light.**Offering weather details**\\n\\nIf the user wants more details like the forecast, precipitation, wind, or an hourly breakdown, I'm happy to provide that! However, I need to be cautious about real-time disclaimers since the tool is our ground truth. It returned just \\\"40 C\\\" without a timestamp, so I'll assume it's current. It could be helpful to include a Fahrenheit conversion, though it might add unnecessary verbosity. I could say, \\\"It's around 40°C (104°F). If you'd like the forecast or humidity/wind, just let me know!\\\"\",\"reasoning_details\":[{\"type\":\"reasoning.summary\",\"summary\":\"**Relaying weather information**\\n\\nI called the weather tool, and it returned \\\"40 C.\\\" That seems unusually high! Since my job is to relay the weather, I should only share the temperature. The user asked for the weather in Florence, Italy, so I can simply say, \\\"It's currently about 40°C in Florence, Italy.\\\" I might want to check in and ask if the user wants more details, but they didn't explicitly ask for them. I'll keep the formatting light.**Offering weather details**\\n\\nIf the user wants more details like the forecast, precipitation, wind, or an hourly breakdown, I'm happy to provide that! However, I need to be cautious about real-time disclaimers since the tool is our ground truth. It returned just \\\"40 C\\\" without a timestamp, so I'll assume it's current. It could be helpful to include a Fahrenheit conversion, though it might add unnecessary verbosity. I could say, \\\"It's around 40°C (104°F). If you'd like the forecast or humidity/wind, just let me know!\\\"\",\"format\":\"openai-responses-v1\",\"index\":0},{\"type\":\"reasoning.encrypted\",\"data\":\"gAAAAABo08lDDT_0SD4rB6oixEWH_r6zDHE_RlvZZCzAuvgmCBqVW-l5bxHiHRVlD9hBPNNPAGGQWlj_NXMLv2RNOlBo_pz1QmYVozDLLcw1CTSQzhHclG2rLwN3d7HzcO_CXRtArTL07jXUoybgpGmrpqQ0C552Dv8lgrSi3z4qdOXGg7gCA8ihXz7HusVh-7cfWTIJrysOaBHkAv8jDOvWhECTFZPKl8Y3tj2VGcqqqiE7ePLCiJfFZ2Ykm1P8z8vN--owy-LHwTyFaTeokkVqhU3j1s2c3UqFBjralVpr0tOyXs06UlPvJEjdaXZBV8LF7_CgZr9md1on2z1aO9cgYSJV3jLbwCIet8Ij_iLweu7JEFpMC_-Vp5y8cXVEyQsEShE9gj-ypD0SNIfr7L2pmbUeY3PMej83sm5Indp3cbRir07ENkhIkOz7J2oN6uo3EWKcc_xXb-qJTAIixe5rDcbyh8ic1hetmWTqKWzOXrTz0xBalNaIH4-QzqdVR0RiG3gVa9MNDTRhGdvb5P5kmL96-o_ldpDnrDvfjVu7ZtmlRw5KkjtuJw0Fl3G4yNVQJi71wdil9I-XKFnJrEWpaG3MT8BiS9tmUDSstWhDGEhIWyP8NuCnHFBKS-NuzUa3ZQacGXhfMEmWdRYuVllwFuOxPxqjOwFfbc17RhX48n9d8qEwyUMIwUdJumXUOEHrB8fTdb3np9yw-A6Df4M9S3hprqTPB0-HGVtcAbWemJgIezenKzV7xtxRm-nD_5Ofz4KLSisHXV7gsJCed3FMpgUdd2OkzsLALaWDRZKvsk1jOh2soLaBjKWt0CNJ0gpHo_j7sLyvgqpIiWNiC_aR2In1DC3rFuZAkpOpqQ6xuh2WWEDWsZL2NR4eVTASZqQLc81lOyjQbrcbZqv--UZTioWytssjLvS7LGFgaXvPwflRnyx1XxtN5yYy1skU64LwZENwvmqxRrTUsG7Mrj3d6n81CSVMWdiREXm4TgudfC_wjJeEt3Iq8HO9qplAvk0hRZVelsYjr72IRbdXJJJuRfGt6Vs8LsxMu0xs9RqF9O0kLpuVZdnixR2fzTSeeHO0Y1-Sz2Cx72ti5D86IyU2XuHtUVzKqL8Wr3lMk-ta_17sMwGtP5iU0OIRK_m7My-R372b-qQtk9ingBGzlwNfBiVsOWqv5w2IRQG_VTx4rwseqbtNU-GZFTXAs9U6J03m9YuXHs-7W8whITzSZ1T8oiLLQcQ9ow9ve0SPcZLrgpoBK6JmiRQ2_fI1mD_boWKIKpX7L4eJKrfvDAStM9Irfgixac12Qcc7gfdp76mCAP4YSYoZJ3nNbxT2dogrGxsLVGRAW_qFZOcUAZT5eFS3q1YBJMXfBpTJb38SGMmtOsdD9Sa-O-9D9fC1fS2ijc1ip_MxWM5pctvEtgUOUPzJW9R_6ewpurLsrmq7dYTYzKSUknj5N1gCg0g0C6Gl6QByMXpKBEGu4M9VCRLpy4ybCb8Qz-WZIRdU0lQBxwl1lbzoSytT5T51IPoJrDYCMsiJgKZGXi0DHFj2bTJXfGDb4ER_U8jGv3gfXuxkhFQEECzGsSQrTyLH2i-j87ETrm9XLH0bs12u_EVq-o8LLdq3TWawKdpaol43civ1EB5eDqjBHdgl6IG3e5xPUEhb8FyTE7sgfbf8FClQjBmoItdZ8DYne1hWM10Ol1hivAaWjz5LZSPs2tA2j2dlwGnC1uI07Bl0CcE-wUNfR8Scr8OJeJgyBDJ0Dt0wZwhU0j7RpKTO8D9YN3OqdXSBqAeW4A3mRV1vSlp48IhcS4Ur4Vyj9x6w6qKiAEL2fjFCe8XUE3fJGpcLDzMMigFLEyUbVBXs9YD_9ZXXhrS1dFRuLEjtYd95sftDFx5r09Nhk5iyH7jTQrYqytdOzHkS9cGLVbBFCeNlQMAqGRG6OI4FQy13NDSqhvxeSRp1wo_TtrdcNHqx8tSCrtpr3owUsLbO2uj8vCRAOL2nAxI9qDEtA-0_jdMJQnr0NBtSsAcHUZHNkwuSGH7-VV14k4hdiJyl1Yt86Iu3WQAcQzSbs-oOYfhGQmHINKUbY-auDZvH_dLVF3unFF6PSZnWQs2gfHp2KQ64F2sm9ve-5N7vlBue3IzaZOJkbprtC9WPDn9M0kqSBL__wvGZB3-86b0NwiGoUBP0v3fMx8U6JpFSj_dtKndvhbKf8oEeCDYtw1e5qaTWB3osgS6UtL7aJoBTynH-y6WSWWwhGYaR2Q7KC6n0amaxLPhZipPDHLA8pPCTKK4wgRBxqZe8UMmmHUub31VqHE_Xf5MnvRq0zSBq4fOlb79FkAqVfgWfj8lUgCi5WMl8yR-jhUqhmCApA7V3rkblrK1gDZOuFLEsGvgTDKMP8JoAKPhn-9iNcMtSlPuLWVferyXI4_PevsXqpHSh46OTneOf8qJ77FdR7Ieq87w26y1xlBJJtTaCgBrr7p0dnawL9GIPfDqXPWEzM4fDQtHBxi8fEzhdC3qJIcW4POkTekGvQucejb_NR8Px3mFDlrMO_9osbUBhv_NH7ajOfmgXfwdc0QakG-oyC7uNU_8Fa3hj0vwpV-PhJyq_a6lMVNonEVOi9VbUX0M=\",\"id\":\"rs_68d3c9390afc81908a6040e78c8d0276\",\"format\":\"openai-responses-v1\",\"index\":0}]}}],\"usage\":{\"prompt_tokens\":92,\"completion_tokens\":288,\"total_tokens\":380,\"cost\":0.0014975,\"is_byok\":false,\"prompt_tokens_details\":{\"cached_tokens\":0,\"audio_tokens\":0},\"cost_details\":{\"upstream_inference_cost\":null,\"upstream_inference_prompt_cost\":0.0000575,\"upstream_inference_completions_cost\":0.00144},\"completion_tokens_details\":{\"reasoning_tokens\":256,\"image_tokens\":0}}}"
        headers:
            Content-Type:
              - application/json
        status: 200 OK
        code: 200
        duration: 755.368166ms
